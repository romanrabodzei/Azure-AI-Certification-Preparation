# Azure AI Engineer Associate

**This certification validates your expertise with Azure AI Engineer Associate.**
<p>
Candidates for this exam should be professionals with experience in designing and implementing AI solutions on Microsoft Azure. This exam is an opportunity to demonstrate proficiency in leveraging Azure AI services to create, manage, and secure AI applications, including integrating them with cognitive services, machine learning, and knowledge-mining tools.
</p>

> [!IMPORTANT]
> **These are NOT real questions from the exam, but quite close enough to what you can get. The goal is to help you prepare and obtain the certification.**

## Skills measured

- Plan and manage an Azure AI solution (15–20% of the exam)
- Implement content moderation solutions (10–15% of the exam)
- Implement computer vision solutions (15–20% of the exam)
- Implement natural language processing solutions (30–35% of the exam)
- Implement knowledge mining and document intelligence solutions (10–15% of the exam)
- Implement generative AI solutions (10–15% of the exam)

## Questions

Q: You have a website that allows users to upload images.
You need to ensure that the uploaded images do not contain adult content. The solution must minimize development effort.
Which service should you use?
<details><summary>Show the answer</summary><p>

- **Azure AI Vision Image Analysis**
> The Azure AI Vision Image Analysis service can extract a wide variety of visual features from an image. One of them is to detect adult content.
The Azure AI Face service provides AI algorithms that detect, recognize, and analyze human faces in images. Azure AI Custom Vision is an image recognition service that lets you build, deploy, and improve own image identifier models. So, while it is possible, it is not the solution with the lowest development effort. Azure AI Vision Spatial Analysis is used to ingest streaming video from cameras, extract insights, and generate events to be used by other systems. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/what-are-cognitive-services) [Source<sup>2</sup>](https://learn.microsoft.com/azure/cognitive-services/computer-vision/overview) [Source<sup>3</sup>](https://learn.microsoft.com/azure/cognitive-services/computer-vision/overview-image-analysis?tabs=3-2) [Source<sup>4</sup>](https://learn.microsoft.com/training/modules/prepare-to-develop-ai-solutions-azure/)
</details>

---
Q: You are building a solution that uses Azure AI Search.
You need to execute the initial run of the indexer.
Which stages will be included during the initial run?
<details><summary>Show the answer</summary><p>

- **Document cracking, field mapping, skillset execution, and output field mapping**
> Document cracking, field mapping, skillset execution, and output field mapping are the stages of indexing.
Creating a data source, creating an index, and creating and running the indexer are the stages to create an indexer. Connecting to an Azure data source, creating an index schema, and running the wizard to create objects and load data are the stages for the Import Data wizard. [Source<sup>1</sup>](https://learn.microsoft.com/azure/search/search-indexer-overview#stages-of-indexing) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/create-azure-cognitive-search-solution/)
</details>

---
Q: You are building a solution that uses Azure AI Search.
You need to save normalized binary files as projections.
Which type of projection should you use?
<details><summary>Show the answer</summary><p>

- **Files**
> Tables are used for data that is best represented as rows and columns, or whenever you need granular representations of your data.
Files are used when you need to save normalized, binary image files. Objects are used when you need the full JSON representation of your data and enrichments in one JSON document. [Source<sup>1</sup](https://learn.microsoft.com/azure/search/knowledge-store-projection-overview#types-of-projections-and-usage) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/create-azure-cognitive-search-solution/)
</details>

---
Q: You are building a knowledge mining solution by using Azure AI Search.
You need to ensure that the solution supports wildcard queries in search requests.
What should you include in the REST API request?
<details><summary>Show the answer</summary><p>

- **“queryType”: “full”**
> queryType “full” extends the default Simple query language by adding support for more operators and query types, such as wildcard, fuzzy, regex, and field-scoped queries. [Source<sup>1</sup>](https://learn.microsoft.com/azure/search/search-lucene-query-architecture) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/create-azure-cognitive-search-solution/)
</details>

---
Q: You are building an app will use Azure AI Search.
You need to index a collection of documents.
What is the first stage of the indexing process?
<details><summary>Show the answer</summary><p>

- **Document cracking**
> Document cracking is the process of opening files and extracting content. It is the first stage of the indexing process.
Text-based content can be extracted from files in a service, rows in a table, or items in a container or collection. If you add a skillset and image skills, document cracking can also extract images and queue them for image processing. [Source<sup>1</sup>](https://learn.microsoft.com/azure/search/search-indexer-overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/create-azure-cognitive-search-solution/)
</details>

---
Q: You have a web app named App1 that performs customs searches.
You are building a solution that uses Azure AI Search.
You need to include App1 as a custom skill as part of the solution.
Which @odata.type should you use to call App1?
<details><summary>Show the answer</summary><p>

- **Microsoft.Skills.Custom.WebApiSkill**
> Microsoft.Skills.Custom.WebApiSkill allows the extensibility of an AI enrichment pipeline by making an HTTP call to a custom web API. [Source<sup>1</sup>](https://learn.microsoft.com/azure/search/cognitive-search-predefined-skills) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/create-enrichment-pipeline-azure-cognitive-search/)
</details>

---
Q: You are building a knowledge mining solution that uses Azure AI Search.
You need to extract content from a file within the enrichment pipeline by using AI enrichment.
Which built-in skill should you use?
<details><summary>Show the answer</summary><p>

- **Microsoft.Skills.Util.DocumentExtractionSkill**
> Microsoft.Skills.Util.DocumentExtractionSkill is the built-in skill used to extract content from a file within the enrichment pipeline. [Source<sup>1</sup>](https://learn.microsoft.com/azure/search/cognitive-search-predefined-skills) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/create-azure-cognitive-search-solution/)
</details>

---
Q: You have an app named App1 that analyzes social media mentions and determines whether comments are positive or negative.
During testing, you notice that App1 generates negative sentiment analysis in response to customer feedback that contains positive feedback.
You need to ensure that App1 includes more granular information during the analysis.
What should you add to the API requests?
<details><summary>Show the answer</summary><p>

- **opinionMining=true**
> opinionMining=true will add aspect-based sentiment analysis, which in turn will make the sentiment more granular so that positive and negative in a single sentence can be returned.
loggingOptOut=true will opt out of logging and StringIndexType=TextElements_v8 will set the returned offset and length values to correspond with TextElements. [Source<sup>1</sup>](https://learn.microsoft.com/rest/api/language/text-analysis-runtime/analyze-text?view=rest-language-2023-04-01&tabs=HTTP) [Source<sup>2</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/sentiment-opinion-mining/how-to/call-api) [Source<sup>3</sup>](https://learn.microsoft.com/training/modules/extract-insights-text-with-text-analytics-service/)
</details>

---
Q: You are building an app that will flag documents that contain the names of staff members by using the Azure AI Language Personally Identifiable Information (PII) detection feature.
You need to configure the PII detection feature.
Which category should you use?
<details><summary>Show the answer</summary><p>

- **Person**
> The Person category detects names of people in the PII detection feature. The PhoneNumber category detects phone numbers, the age category detects people’s ages, and the DateTime detects dates and time values. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/personally-identifiable-information/concepts/entity-categories) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/publish-use-language-understand-app/)
</details>

---
Q: You need to build an app that will summarize text documents into key phrases.
Which Azure AI Language feature should you recommend?
<details><summary>Show the answer</summary><p>

- **Key phrase extraction**
> Key phrase extraction is used to quickly identify the main concepts in text, whereas the other features do not return key phrases from longer text documents. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/key-phrase-extraction/overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/extract-insights-text-with-text-analytics-service/)
</details>

---
Q: You have an app that sends audio recordings from a call center to the speech-to-text feature of Azure AI Services.
During testing, you notice that the Word Error Rate (WER) is high and there are a lot of substitution errors.
You need to improve the model and reduce the WER.
What should you add to the training data?
<details><summary>Show the answer</summary><p>

- **Custom product and people names**
> Substitution errors are due to the model needing more training on custom product names and people names.
Overlapping speakers define when there are more deletion errors. People talking in the background are detected when there are more insertion errors. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/speech-service/how-to-custom-speech-evaluate-data?pivots=speech-studio#resolve-errors-and-improve-wer) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/transcribe-speech-input-text/)
</details>

---
Q: You are building an app that will analyze meeting recordings and identify who is speaking at which moment in time.
You need to configure a voice profile for the app.
Which type of voice profile should you use?
<details><summary>Show the answer</summary><p>

- **Speaker identification**
> Text-independent verification means that speakers can speak in everyday language in enrollment and verification phases.
Text-dependent verification means that speakers need to choose the same passphrase to use during both enrollment and verification phases. This is the voice profile that should be used when configuring a voice profile for the app.
Speaker identification helps you determine an unknown speaker’s identity within a group of enrolled speakers. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/speech-service/speaker-recognition-overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/transcribe-speech-input-text/)
</details>

---
Q: You are building an app that will enable users to create notes by using speech.
You need to recommend the Azure AI Speech service model to use. The solution must support noisy environments.
Which model should you recommend?
<details><summary>Show the answer</summary><p>

- **Custom speech-to-text**
> The custom speech-to-text model is correct, as you need to adapt the model because a factory floor might have ambient noise, which the model should be trained on. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/speech-service/faq-stt) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/transcribe-speech-input-text/)
</details>

---
Q: You plan to build an app that will transcribe large quantities of audio files by using the Azure AI Speech service batch transcription feature.
You need to recommend a storage solution for the audio files. The solution must minimize development effort.
What should you recommend?
<details><summary>Show the answer</summary><p>

- **Azure Storage**
> Azure Storage is the only storage provider that can be used by default for batch transcription. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/speech-service/batch-transcription-create?pivots=speech-cli) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/transcribe-speech-input-text/)
</details>

---
Q: You are building an app that will recognize the intent and entities of user utterances in real-time.
You need to implement the pattern matching intent recognition mechanism. The solution must only detect entities that you define in a catalog of phrases.
Which entity type should you use?
<details><summary>Show the answer</summary><p>

- **The List entity using Strict mode**
> The List entity is made up of a list of phrases that will guide the engine on how to match the text. When an entity has an ID of type List and is in Strict mode, the engine will only match if the text in the slot appears in the list. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/speech-service/pattern-matching-overview#types-of-entities) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/transcribe-speech-input-text/)
</details>

---
Q: You are building a custom translation model.
You need to use bilingual training documents to teach the model your terminology and style.
Which rule should you follow?
<details><summary>Show the answer</summary><p>

- **Be liberal**
> Be liberal is correct. Any in-domain human translation is better than machine translation. Add and remove documents as you go and try to improve the Bilingual Evaluation Understudy (BLEU) score.
Be strict is incorrect. Compose them to be optimally representative of what you are going to translate in the future. Be restrictive is also incorrect. A phrase dictionary is case-sensitive, and any word or phrase listed is translated in the way you specify. In many cases, it is better to not use a phrase dictionary and let the system learn. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/translator/custom-translator/beginners-guide#what-should-i-use-for-training-material) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/translate-text-with-translator-service/)
</details>

---
Q: You are building a custom translation model.
You need to evaluate the precision of the text that you translated by using a Bilingual Evaluation Understudy (BLEU) score.
Which scale is used for the score?
<details><summary>Show the answer</summary><p>

- **Between 0 and 100**
> A BLEU score is a number between zero and 100. A score of zero indicates a low-quality translation, where nothing in the translation matches the reference. A score of 100 indicates a perfect translation that is identical to the reference. It is unnecessary to attain a score of 100. A BLEU score between 40 and 60 indicates a high-quality translation. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/translator/custom-translator/beginners-guide#what-is-a-bleu-score) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/translate-text-with-translator-service/)
</details>

---
Q: You are using Azure AI Translator to translate documents from one language to another.
You need to extend the capabilities of an application by using the Azure AI Translator service.
Which three features are available in the Translator service? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Detect language**
- **Dictionary lookup**
- **Transliterate**
> Apart from translation, the following features are part of Translator: Transliterate, Detect, Dictionary lookup, and Dictionary example. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/translator/text-translation-overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/translate-text-with-translator-service/)
</details>

---
Q: You are building an Azure AI Translator custom model.
You need to ensure that the translation accuracy for the model has a Bilingual Evaluation Understudy (BLEU) score that indicates high quality.
What is the minimum score range required?
<details><summary>Show the answer</summary><p>

- **40 to 59**
> between 40 and 60 indicates a high-quality translation. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/translator/custom-translator/key-terms) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/translate-text-with-translator-service/)
</details>

---
Q: You are building a model that uses Conversational Language Understanding (CLU).
You need to train the model.
Which training methods can you use?
<details><summary>Show the answer</summary><p>

- **Standard and advanced only**
> Both standard and advanced are from CLU. Deterministic is a method from Language Understanding. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/conversational-language-understanding/how-to/train-model?tabs=language-studio#training-modes) [Source<sup>2</sup>](https://learn.microsoft.com/azure/cognitive-services/luis/how-to/train-test#change-deterministic-training-settings-using-the-version-settings-api) [Source<sup>3</sup>](https://learn.microsoft.com/training/modules/build-language-understanding-model/)
</details>

---
Q: You are creating an orchestration workflow for Language Understanding.
You need to configure workflows for multiple languages. The solution must minimize administrative effort.
What should you create for each language?
<details><summary>Show the answer</summary><p>

- **Separate workflow projects**
> Orchestration workflow projects do not support the multilingual option, so you need to create a separate workflow project for each language. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/orchestration-workflow/language-support) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/build-language-understanding-model/)
</details>

---
Q: You are building an orchestration workflow to orchestrate and connect multiple Language Understanding models and question answering projects for use in a bot.
Which two operations can you perform in an orchestration workflow based on Azure AI Language service? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Connect to Language Understanding applications that are owned by the same resource as the orchestration workflow**
- **Connect to question answering projects that are in the same Azure AI Language service resource as your orchestration workflow**
> Adding entities to your orchestration workflow is not allowed. Entities are mutually exclusive within an orchestration workflow. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/orchestration-workflow/faq) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/build-language-understanding-model/)
</details>

---
Q: You plan to build a chatbot that will help users answer FAQs.
You need to identify which scenarios are suitable for use with the Azure AI Language question answering service.
Which three scenarios should you identify? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **When you have a bot conversation that includes static information**
- **When you have static information in a knowledge base of answers**
- **When you need to provide the same answer to a request, question, or command**
> Question answering only works with static information, not with dynamic information. In addition, it will always provide the same answer to the same question. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/question-answering/overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/build-qna-solution-qna-maker/)
</details>

---
Q: You are building a chatbot that will use the Azure AI Language question answering service.
You need to identify the operational costs for the service.
Which two parameters will influence the costs? Each correct answer presents a complete solution
<details><summary>Show the answer</summary><p>

- **The required throughput**
- **The size and the number of knowledge bases**
> The throughput, the size, and the number of knowledge bases affect the pricing tier, whereas the other parameters do not affect pricing. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/question-answering/concepts/azure-resources) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/build-qna-solution-qna-maker/)
</details>

---
Q: You are building an app that will detect the color scheme of uploaded images.
You are evaluating using the Image Analysis API to detect the dominant background color of an image.
Which color can the API return as a dominant background color?
<details><summary>Show the answer</summary><p>

- **Teal**
> Only a certain set of colors can be returned by the API. The set of possible returned colors is black, blue, brown, gray, green, orange, pink, purple, red, teal, white, and yellow. [Source](https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-detecting-color-schemes)
</details>

---
Q: You are building an app that will use Azure AI Vision to detect the presence of people in a video feed.
Which Azure AI Vision feature should you use?
<details><summary>Show the answer</summary><p>

- **Spatial Analysis**
> The only visual feature that provides this capability is Spatial Analysis, as OCR, Image Analysis, and face detection are not meant to analyze the presence of people in a video feed. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/computer-vision/overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/analyze-video/)
</details>

---
Q: You have an app named App1 that extracts invoice data from PDF files by using an S0 instance of Azure AI Document Intelligence. The PDF files are up to 2 MB each and contain up to 10 pages.
Users report that App1 is unable to process some invoices.
You need to troubleshoot the issue.
What is a possible cause of the issue?
<details><summary>Show the answer</summary><p>

- **Some of the files are password protected.**
> The service cannot process password-protected files, and this can cause the service a processing failure for some of the files. Although file size and number of pages can cause failures, the limit for the S0 tier is 500 MB and 2,000 pages.
The S0 tier is sufficient for the file characteristics mentioned. [Source<sup>1</sup>](https://learn.microsoft.com/azure/applied-ai-services/form-recognizer/concept-invoice?view=form-recog-3.0.0) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/work-form-recognizer/)
</details>

---
Q: You are building an app that will use the Azure AI Custom Vision API to detect when all the spaces in a parking lot are empty.
Which feature of the API should you use?
<details><summary>Show the answer</summary><p>

- **Object detection**
> Object detection is similar to image classification, but it returns the coordinates in an image where the applied label(s) can be found.
Image description analyzes an image and generates a human-readable phrase that describes its contents. Image classification applies one or more labels to an entire image. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/custom-vision-service/overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/detect-objects-images/)
</details>

---
Q: You need to build an app that will use Azure AI Vision to analyze and detect animals in images.
Which type of project should you use?
<details><summary>Show the answer</summary><p>

- **Object detection**
> Object detection returns the coordinates in an image where the applied label(s) can be found, while image classification applies one or more labels to an entire image. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/custom-vision-service/overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/detect-objects-images/)
</details>

---
Q: You are building an app that uses Azure AI Video Indexer.
You need to extract keyframes from uploaded video and store them on a disk by using the API.
How should you implement the solution?
<details><summary>Show the answer</summary><p>

- **Upload the video, get the video index, and get the thumbnail for each keyframe.**
> You need to upload the video, get the video index, and get the thumbnail for each keyframe. Three API calls need to be done.
Uploading the video, and then downloading the ZIP file of the thumbnails is the path through the Azure portal. You need the index to know the correct parameters for the thumbnail request. [Source<sup>1</sup>](https://learn.microsoft.com/azure/azure-video-indexer/scenes-shots-keyframes) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/analyze-video/)
</details>

---
Q: You are using a custom Language content model in an Azure AI Video Indexer solution.
During testing, you upload a text file that includes the following sentence: “Kubernetes is a new feature in Azure & the cloud.”
The sentence is discarded.
You need to ensure that the model retains the sentence.
What should you do?
<details><summary>Show the answer</summary><p>

- **Remove the “&” character from the text file**
> You need to remove the “&” character because sentences with special characters will be discarded.
Kubernetes is highly specific and unknown to the model, so retraining the model is incorrect. The slate model is for clapper boards and digital patterns with color bars. [Source<sup>1</sup>](https://learn.microsoft.com/azure/azure-video-indexer/customize-language-model-overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/analyze-video/)
</details>

---
Q: You are building a video processing app that will use Azure AI Video Indexer.
You need to configure the training and learning phases for the app. The solution must train the model based on the probability of specific word combinations by using a custom Language model.
Which three practices should be followed for the training data? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Include multiple examples of spoken sentences.**
- **Provide multiple adaptation options.**
- **Put only one sentence per line.**
> When training the model, you should avoid repeating an identical sentence multiple times, as it may create bias against the rest of the input.
You should avoid including uncommon symbols (~, # @ % &), as they will be discarded. The sentences in which they appear will also be discarded.
You should also avoid putting inputs that are too large, such as hundreds of thousands of sentences, because doing so will dilute the effect of boosting. [Source<sup>1</sup>](https://learn.microsoft.com/azure/azure-video-indexer/customize-language-model-overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/analyze-video/)
</details>

---
Q: You are building a video processing app that will use Azure AI Video Indexer to extract insights from videos that contain multi-language content.
You need to configure the API calls to enable multilingual identification.
Which value should you set for the sourceLanguage parameter?
<details><summary>Show the answer</summary><p>

- **Multi-language detection**
> When indexing or reindexing a video by using the API, choose the multi-language detection option for the sourceLanguage parameter. The remaining options do not configure the API calls to enable multilingual identification. [Source<sup>1</sup>](https://learn.microsoft.com/azure/azure-video-indexer/multi-language-identification-transcription) [Source<sup>2</sup>](https://learn.microsoft.com/azure/azure-video-indexer/multi-language-identification-transcription) [Source<sup>3</sup>](https://learn.microsoft.com/training/modules/analyze-video/)
</details>

---
Q: You plan to implement a solution to extract information from documents by using Azure AI Document Intelligence and use prebuilt models where possible.
You need to identify the prebuilt models available in Azure AI Document Intelligence.
Which three models are available? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Invoice**
- **Receipt**
- **W-2**
> Except for meeting minutes and time sheets, all the other models are prebuilt models in Azure AI Document Intelligence. Meeting minutes and time sheets must be added to Azure AI Document Intelligence. as custom models. [Source](https://learn.microsoft.com/training/modules/use-prebuilt-form-recognizer-models/4-use-financial-id-tax-models)
</details>

---
Q: You are building a mobile app that will enable users to scan street signs and will read out the text on the sign.
You need to recommend a service to use. The solution must minimize development effort.
Which service should you recommend?
<details><summary>Show the answer</summary><p>

- **Azure AI Vision**
> Azure AI Vision is the only service which can achieve the desired result.
Azure AI Custom Vision and Azure AI Face do not offer OCR. Azure AI Document Intelligence is designed for documents, but not images. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/computer-vision/overview-ocr) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/read-text-images-documents-with-computer-vision-service/)
</details>

---
Q: You are building an app that will extract text from scanned receipts.
You need to recommend which service to use. The solution must minimize development effort.
What should you recommend?
<details><summary>Show the answer</summary><p>

- **Azure AI Document Intelligence**
> Azure AI Document Intelligence is designed to work with documents such as receipts, as it offers prebuilt models for extracting information from these kinds of documents. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/computer-vision/overview-ocr) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/work-form-recognizer/)
</details>

---
Q: You are building an Azure AI Language solution.
You need to deploy the solution to a location without internet connectivity.
What should you do?
<details><summary>Show the answer</summary><p>

- **Deploy the solution to a Docker host container.**
> You can use disconnected containers to host Language Understanding on-premises.
There is no virtual machine set up to run a Language Understanding instance and a standard instance still has Language Understanding running in the cloud. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/containers/disconnected-containers) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/investigate-container-for-use-cognitive-services/)
</details>

---
Q: You are building an app that will use an Azure AI Services resource.
You need to identify the endpoint for the resource.
From the Azure CLI, which command should you run?
<details><summary>Show the answer</summary><p>

- **az cognitiveservices account show --name myresource --resource-group cognitive-services-resource-group**
> As you need to provide the name and the resource group for your Cognitive Service account to retrieve the endpoint amongst other information for the resource, az cognitiveservices account show --name myresource --resource-group cognitive-services-resource-group is the only valid command. [Source<sup>1</sup>](https://learn.microsoft.com/cli/azure/cognitiveservices/account?view=azure-cli-latest#az-cognitiveservices-account-show) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/create-manage-cognitive-services/)
</details>

---
Q: You are building an app that will use Azure AI Custom Vision. The app will be deployed to a virtual machine in Azure.
You enable firewall rules for your Azure AI Services account.
You need to ensure that the app can access the service through a service endpoint.
What should you do?
<details><summary>Show the answer</summary><p>

- **Grant access to a specific virtual network.**
> If you enable the firewall for the Azure AI Services account, you need to allow network access to the service. You can achieve this by either allowing access from a specific virtual network or adding an IP range to the firewall rules. In this situation, the app is deployed to a virtual machine in Azure, which resides in a virtual network. You can provide access to virtual networks in Azure to access specific service endpoints. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/cognitive-services-virtual-networks?context=%2Fazure%2Fcognitive-services%2Fcustom-vision-service%2Fcontext%2Fcontext&tabs=portal) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/secure-cognitive-services/)
</details>

---
Q: You have an Azure App Services web app named App1.
You need to configure App1 to use Azure AI Services to authenticate by using Microsoft Entra ID. The solution must meet the following requirements:
Minimize administrative effort.
Use the principle of least privilege.
What should you do?
<details><summary>Show the answer</summary><p>

- **From App1, enable a managed identity and assign role-based access control (RBAC) permissions to Azure AI Services.**
> With a managed identity, the rotation of the secrets (certificates) is done automatically.
You still need to rotate secrets by using the key vault, and you cannot create secrets that never expire from the portal. It is not considered best practice to create one with PS1 or the CLI, and a certificate will also expire at some point. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/authentication?tabs=powershell#authorize-access-to-managed-identities) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/secure-cognitive-services/)
</details>

---
Q: You have an Azure AI Services resource.
You need to enable diagnostic logging.
What are two prerequisites for diagnostic logging? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **A Log Analytics workspace**
- **An Azure Storage account**
> The prerequisites to enable diagnostic logging are to have an Azure Storage resource that retains diagnostic logs for policy audit, static analysis, or backup. A Log Analytics resource provides a flexible log search and analytics tool that allows for analysis of raw logs generated by an Azure resource. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/diagnostic-logging) [Sourc<sup>2</sup>](https://learn.microsoft.com/training/modules/monitor-cognitive-services/)
</details>

---
Q: You are developing a containerized optical character recognition (OCR)-capable application by using Azure AI Services containers.
While developing the solution, you retrieve a status message of “Mismatch”, and the connection to the AI Services resource fails.
You need to ensure that the solution can connect to the AI Services resource.
What should you do?
<details><summary>Show the answer</summary><p>

- **Confirm that the API key is for the correct resource type.**
> Mismatch means that the wrong API key has been used. If you have provided an API key or endpoint for a different kind of Azure AI Services resource, you find your API key and service region in the Azure portal, in the Keys and Endpoint section for your Azure AI Services resource.
If the API key is invalid, you must confirm that the API key is for the correct region. If the API key has exceeded the quota, then you can either upgrade your pricing tier or wait for an additional quota to become available. Find your tier in the Azure portal, in the Pricing Tier section of your Azure AI Service resource. The mismatch error would not be generated if the resource was offline. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/containers/container-faq) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/investigate-container-for-use-cognitive-services/)
</details>

---
Q: You have an Azure OpenAI solution. The solution uses a specific GPT-35-Turbo model version that was current during initial deployment. Auto-update is disabled.
Sometime later, you investigate the deployed solution and discover that it uses a newer version of the model.
Why was the model version updated?
<details><summary>Show the answer</summary><p>

- **The model version reached its retirement date.**
> As your use of Azure OpenAI evolves, and you start to build and integrate with applications, you might want to manually control model updates so that you can first test and validate whether model performance remains consistent for a use case before performing an upgrade.
When you select a specific model version for a deployment, this version will remain selected until you either choose to manually update it, or once you reach the retirement date of the model. When the retirement date is reached, the model will upgrade to the default version automatically at the time of retirement. [Source](https://learn.microsoft.com/azure/ai-services/openai/how-to/working-with-models?tabs=powershell)
</details>

---
Q: You are creating an application that references the Azure OpenAI REST API for a DALL-E model.
You plan to use thumbnails of the images that DALL-E generates and display them in a table on a webpage.
You need to find the image URLs in the JSON response.
Which element should you review?
<details><summary>Show the answer</summary><p>

- **The result element**
> The result from the initial request does not immediately return the results of the image generation process. Instead, the response includes an operation-location header with a URL for a callback service that your application code can poll until the results of the image generation are ready. The result element includes a collection of url elements, each of which references a PNG image file generated from the prompt. [Source](https://learn.microsoft.com/training/modules/generate-images-azure-openai/4-dall-e-rest-api)
</details>

---
Q: You are building a web app that will generate images based on user prompts. The app will use the DALL-E 3 Azure OpenAI model.
You need to ensure that HTTP requests against the Azure OpenAI API successfully generate images.
Which three HTTP header properties should you include? Each correct answer presents part of the solution.
<details><summary>Show the answer</summary><p>

- **The API version used in this operation**
- **The name of the Azure OpenAI service resource**
- **The name of the Azure OpenAI service resource**
> The name of the Azure OpenAI resource, the name of the DALL-E 3 model deployment, and the API version to be used are the three required header properties for HTTP requests. The other answers are valid for use in the HTTP body but not the header. [Source](https://learn.microsoft.com/azure/ai-services/openai/reference)
</details>

---
Q: You are deploying an Azure OpenAI service.
You plan to use your own data in the models you will deploy.
You need to ensure that the model can index your data sources.
Which additional Azure service should you deploy?
<details><summary>Show the answer</summary><p>

- **Azure AI Search**
> Azure OpenAI on your data enables developers to use supported AI chat models that can reference specific sources of information to ground the response. Adding this information allows the model to reference both the specific data provided and its pretrained knowledge to provide more effective responses. Azure OpenAI on your data utilizes the search ability of Azure AI Search to add the relevant data chunks to a prompt.
Azure OpenAI on your data still uses a stateless API to connect to the model, which removes the requirement of training a custom model with your data and simplifies the interaction with the AI model. Cognitive Search first finds the useful information to answer the prompt, and Azure OpenAI forms the response based on that information. [Source<sup>1</sup>](https://learn.microsoft.com/training/modules/use-own-data-azure-openai/2-understand-use-own-data) [Source<sup>2</sup>](https://learn.microsoft.com/azure/ai-services/what-are-ai-services)
</details>

---
Q: You are building a GPT-based chat application that will answer questions about your company.
You plan to use the Using your data feature in Azure OpenAI to ground the model with company data.
Which four types of files can you use to ground the model? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **HTML**
- **MD**
- **PDF**
- **TXT**
> Currently only TXT, MD, HTML, PDF, Microsoft Word, and PowerPoint files can be used and are supported using the “Using your data” feature in Azure OpenAI. ZIP and XML files are not supported. [Source](https://learn.microsoft.com/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search)
</details>

---
Q: You are building a GPT-based chat application that will answer questions about your company.
You plan to use the Using your data feature in Azure OpenAI to ground the model with your company data.
While testing, you discover that some responses are not accurate enough.
You need to configure the Azure OpenAI resource to filter out less-relevant documents for responses.
Which parameter should you configure?
<details><summary>Show the answer</summary><p>

- **Strictness**
> The Strictness parameter sets the threshold to categorize documents as relevant to your queries. Raising the Strictness parameter value means a higher threshold for relevance and filters out more less-relevant documents for responses. Retrieved documents specifies the number of top-scoring documents from your data index used to generate responses. Content data specifies the fields in your index that contain the main text content of each document. File name specifies the field in your index that contains the original file name of each document. [Source](https://learn.microsoft.com/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search)
</details>

---
Q: You are building a GPT-based chat application that will answer questions about your company.
You plan to test the application by using strategies defined by Microsoft best practices.
Which three prompt engineering strategies should you consider while testing the application? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Be Descriptive**
- **Be Specific**
- **Order Matters**
> Be Specific means to leave as little to interpretation as possible. Be Descriptive means to use analogies. Order Matters means that the order in which you present information to the model can affect the output. Therefore, those three are valid best practices. Be simple and be minimalistic do not produce the best results and are, therefore, not best practices. [Source](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering)
</details>

---
Q: You are creating an application that will use Azure OpenAI REST API services. The application uses a REST call to a DALL-E model to generate images. The three parameters in the REST call are prompt, n, and size.
What does the size parameter indicate?
<details><summary>Show the answer</summary><p>

- **The size of the images in pixel resolution**
> To make a REST call to the services, you need the endpoint and authorization key for the Azure OpenAI service resource you provisioned in Azure. You initiate the image generation process by submitting a POST request to the service endpoint that has the authorization key in the header. The request must contain the following parameters in a JSON body:
`prompt`: The description of the image to be generated
`n`: The number of images to be generated
`size`: The resolution of the image to be generated (256x256, 512x512, or 1024x1024)
[Source](https://learn.microsoft.com/training/modules/generate-images-azure-openai/4-dall-e-rest-api)
</details>

---
Q: You are an AI engineer tasked with creating a Cognitive Services resource programmatically in the East US Azure region. The resource will be used to analyze text for sentiment analysis. Which code should you use?
<details><summary>Show the answer</summary><p>

- **create_resource(client, "textAnalysis", "TextAnalytics", "F0", "eastus")**
> The TextAnalytics kind with the F0 account tier and eastus location is suitable for sentiment analysis, and it ensures that the resource is free.
</details>

----
Q: You are an AI engineer at a food production factory. You need a solution to monitor staff compliance with PPE requirements, specifically identifying those without masks or safety glasses, every 15 minutes. The solution must minimize development effort and costs. Which service should you use?
<details><summary>Show the answer</summary><p>

- **Azure AI Face service**
> The Azure AI Face service can detect the presence of masks and safety glasses, making it an ideal choice for monitoring PPE compliance with minimal development effort and cost
</details>

----
Q: You are an AI engineer at a company with an Azure bot named botX, which uses a Language Understanding resource named luX. You need to ensure that botX adheres to the Microsoft responsible AI principle of inclusiveness. What should you add to botX?
<details><summary>Show the answer</summary><p>

- **Add Direct Line Speech to botX**
> Adding Direct Line Speech to botX enables voice interaction, making the bot more accessible to users with different needs, such as those with visual impairments, thereby promoting inclusiveness
</details>

----
Q: An AI engineer is developing a customer service chatbot that will process text and video interactions from a company's website. The engineer plans to notify users whenever their data has been processed by the chatbot. Which responsible AI principle does this help meet?
<details><summary>Show the answer</summary><p>

- **Transparency**
> Notifying users that their data has been processed aligns with the principle of transparency, which involves being open about how data is used and processed
</details>

----
Q: You are an AI engineer at a social media company responsible for ensuring that user-generated content adheres to community guidelines. You need to implement a solution that automatically moderates images and text content for offensive or harmful material. Which service should you include in your solution?
<details><summary>Show the answer</summary><p>

- **Azure AI Content Safety**
> Azure AI Content Safety is designed specifically to detect and moderate offensive or harmful content in both images and text, making it ideal for ensuring content adheres to community guidelines
</details>

----
Q: You are building an app that will use the Azure AI Speech service. You need to ensure that the app can authenticate to the service using a Microsoft Entra ID token. Which two actions should you perform?
<details><summary>Show the answer</summary><p>

- **Configure a custom subdomain**
> Configuring a custom subdomain allows you to secure the Speech service endpoint with a domain that is controlled and trusted
- **Create a private endpoint**
> Creating a private endpoint ensures that access to the Speech service is restricted to resources within the virtual network, enhancing security
</details>

----
Q: You are a data scientist managing an Azure AI Search (formerly Azure Cognitive Search) service . Over the past year, the volume of queries has increased steadily, and some search queries are now being throttled. How can you reduce the likelihood of query throttling?
<details><summary>Show the answer</summary><p>

- **Migrate the service to a higher tier**
> Migrating to a higher tier can provide more resources and better performance, reducing the likelihood of query throttling
</details>

----
Q: You are an AI engineer tasked with indexing a collection of historical documents stored as PDF files. The solution must allow for full-text search on the contents of these documents. You need to create an indexer with a skillset.
Which skill should you include?
<details><summary>Show the answer</summary><p>

- **document extraction**
> Document extraction is used to extract text from documents, making it possible to index and search the contents
</details>

----
Q: A developer at Northwind Traders needs to deploy a language model for their chatbot application. Which Azure AI service should they use to select and deploy this model?
<details><summary>Show the answer</summary><p>

- **Azure OpenAI Service**
> Azure OpenAI Service is designed for selecting and deploying advanced language models, making it suitable for applications like chatbots
</details>

----
Q: You are an AI engineer developing a solution that uses Sentiment Analysis results from customer surveys to calculate bonuses for customer service staff. To align with Microsoft responsible AI principles, what should you do?
<details><summary>Show the answer</summary><p>

- **Add a human review and approval step before making decisions that affect staff's financial situation**
> Adding a human review and approval step ensures that decisions affecting financial outcomes are fair and can address potential biases or errors in the AI system, adhering to responsible AI principles
</details>

----
Q: A financial analyst at a logistics company needs to automate the extraction of key information such as invoice number, date, and total amount from invoices in multiple languages. The solution should be quick to implement and require minimal development effort. Which Azure service should be used?
<details><summary>Show the answer</summary><p>

- **Form Recognizer (Azure AI Document Intelligence)**
> This service is designed to extract structured data from documents such as invoices, receipts, and forms with minimal configuration and development effort
</details>

----
Q: You have a Custom Vision resource named acvdev in a development environment. You have a Custom Vision resource named acvprod in a production environment. In acvdev, you build an object detection model named obj1 in a project named proj1. You need to move obj1 to acvprod.
Which three actions should you perform in sequence?

Actions:
- Use the ExportProject endpoint on acvdev.
- Use the GetProjects endpoint on acvdev.
- Use the ImportProject endpoint on acvprod.
- Use the ExportIteration endpoint on acvdev.
- Use the GetIterations endpoint on acvdev.
- Use the UpdateProject endpoint on acvprod.
<details><summary>Show the answer</summary><p>

- **Use the GetProjects endpoint on acvdev**
- **Use the ExportProject endpoint on acvdev**
- **Use the ImportProject endpoint on acvprod**
</details>

----
Q: You are an AI engineer developing an app that manages feedback. You need to ensure that the app can detect negative comments using the Sentiment Analysis API in Azure AI Language while ensuring that the managed feedback remains on your company’s internal network. Which three actions should you perform in sequence?
<details><summary>Show the answer</summary><p>

- **Provision the Language service resource in Azure**
- **Deploy a Docker container to an on-premises server**
- **Run the container and query the prediction endpoint**
</details>

----
Q: You are a data engineer with an Azure AI Search instance that indexes invoices using Azure AI Document Intelligence. To analyze the extracted information in Microsoft Power BI, you need a solution that minimizes development effort. What should you add to the indexer?
<details><summary>Show the answer</summary><p>

- **A table projection**
> Adding a table projection to the indexer allows you to structure the extracted data in a tabular format, which can be directly imported into Power BI for analysis, minimizing the development effort
</details>

----
Q: You have an Azure OpenAI resource named AI1 that hosts three deployments of the GPT-3.5 model. Each deployment is optimized for a unique workload. You plan to deploy three apps. Each app will access AI1 by using the REST API and will use the deployment that was optimized for the app's intended workload. You need to provide each app with access to AI1 and the appropriate deployment. The solution must ensure that only the apps can access AI1. What should you use to provide access to AI1, and what should each app use to connect to its appropriate deployment?
<details><summary>Show the answer</summary><p>

- **Provide access to AI1 by using: An API key**
- **Connect to the deployment by using: A deployment endpoint**
> An API key: This provides secure access to the Azure OpenAI resource, ensuring that only the authorized apps can access AI1.
A deployment endpoint: Each app needs to connect to its specific deployment optimized for its workload. Using the deployment endpoint ensures the app interacts with the correct deployment
</details>

----
Q: An AI engineer is building a language understanding model to search for contact information using an intent named FindContact. A list of phrases provided for training includes:
- Find contacts in New York.
- Who do I know in Berlin?
- Search for contacts in Tokyo.
The engineer needs to implement this phrase list in Language Understanding.
What should be done?
<details><summary>Show the answer</summary><p>

- **Create a new utterance for each phrase in the FindContact intent**
> Create a new utterance for each phrase in the FindContact intent. This ensures that the model is trained to recognize and understand each specific phrase, improving its ability to handle similar queries effectively
</details>

----
Q: A data scientist is training a Language Understanding model for a customer support chatbot. They have created an intent named RetrieveOrderDetails and added 300 examples. To ensure the model accurately identifies relevant queries and reduces false positives, what should the data scientist do?
<details><summary>Show the answer</summary><p>

- **Add examples to the None intent**
> Add examples to the None intent. Including examples in the None intent helps the model distinguish between queries that do not fit any of the defined intents, thereby reducing false positives by providing a clearer distinction between relevant and irrelevant queries
</details>

----
Q: You are developing an internet-based training solution for remote learners. Your company wants to verify whether learners are present during the training sessions. Which Azure Cognitive Services should you use to analyze video feeds to detect learner presence?
<details><summary>Show the answer</summary><p>

- **Face API**
> The Face API is specifically designed to detect and recognize faces in video feeds, making it ideal for verifying the presence of learners
</details>

----
Q: You want to detect whether learners are talking during remote training sessions by analyzing audio feeds. Which Azure Cognitive Services should you use for this task?
<details><summary>Show the answer</summary><p>

- **Speech to Text**
> The Speech to Text service can transcribe spoken words from audio feeds, making it ideal for detecting if learners are talking
</details>

----
Q: An AI engineer is developing a method for an application that uses the Translator API. The method will translate webpage content into Greek (el) and include a transliteration using the Roman alphabet.
Which three query parameters should the engineer include in the URI for the Translator API call?
<details><summary>Show the answer</summary><p>

- **to=el**
> to=el specifies the target language as Greek
- **textType=html**
> textType=html ensures the content is treated as HTML for accurate translation of web content
- **toScript=Latn**
> toScript=Latn specifies the transliteration of the translated content into the Roman alphabet
</details>

----
Q: A data engineer is developing a tool using Azure AI Language. They need to upload a custom vocabulary file to improve the recognition of industry-specific terms.
Which file format should the data engineer use for uploading the custom vocabulary?
<details><summary>Show the answer</summary><p>

- **TXT**
> Azure AI Language supports TXT files for uploading custom vocabulary, making it the suitable format for this task
</details>

----
Q: You are developing an app that uses the Azure AI Vision API to analyze images. You need to ensure the app provides descriptions in complete sentences for users who are vision impaired. Which API call should you use?
<details><summary>Show the answer</summary><p>

- **describeImageInStreamAsync**
> The describeImageInStreamAsync API call generates detailed descriptions of images in complete sentences, making it suitable for providing outputs that are accessible to vision-impaired users
</details>

----
Q: You are an AI engineer with an Azure AI Search solution and a collection of product descriptions that include a category field. You need to index the descriptions to:
- Include the category field in the search results.
- Ensure users can search for terms in the category field.
- Allow users to filter results based on category.
Which index attributes should you configure for the category field?
<details><summary>Show the answer</summary><p>

- **searchable, facetable, and retrievable**
> Configuring the category field as searchable, facetable, and retrievable ensures it can be included in search results, searched for specific terms, and used for drill-down filtering
</details>

----
Q: You have an Azure OpenAI model named AI1. You are building a web app named App1 using the Azure OpenAI SDK. You need to configure App1 to connect to AI1. What information must you provide?
<details><summary>Show the answer</summary><p>

- **The deployment name, endpoint, and key**
> To connect App1 to the Azure OpenAI model AI1, you need to provide the deployment name to specify which deployment to use, the endpoint to connect to the Azure OpenAI resource, and the key for authentication
</details>

----
Q: You are an AI engineer developing a language model using the Language Understanding (classic) service. After creating a new Language Understanding resource, you need to add more contributors. How can you achieve this?
<details><summary>Show the answer</summary><p>

- **Use the Access control (IAM) page for the authoring resources in the Azure portal**
> To add contributors to your Language Understanding (LUIS) resource, you should use the Access control (IAM) page for the authoring resources. This allows you to assign the necessary roles to users for managing and collaborating on the LUIS models
</details>

----
Q: A developer is tasked with implementing a text moderation solution for an online community platform using Azure AI Content Safety. The platform needs to automatically detect and moderate offensive language in user-submitted comments.
What should the developer do to implement this solution?
<details><summary>Show the answer</summary><p>

- **Use the Text Moderation API to analyze user comments for offensive content**
> Use the Text Moderation API to analyze user comments for offensive content. This API is specifically designed to detect and moderate offensive language in text, making it the appropriate tool for this task
</details>

----
Q: You are developing a containerized version of a sentiment analysis API for local testing and on-premises deployment. The API should meet the following requirements:
- Prevent sensitive information from being stored in command-line histories.
- Control access using Azure role-based access control (Azure RBAC).
Which steps should you include in the development process?
<details><summary>Show the answer</summary><p>

- **Push the image to an Azure container registry**
> Push the image to an Azure container registry (ACR). Using Azure container registry with role-based access control helps in managing and securing your container images
- **Build the image**
> Build the image. Building the image from the Dockerfile is a crucial step to create the customized container for deployment
- **Create a custom Dockerfile**
> Create a custom Dockerfile. Creating a custom Dockerfile allows you to configure the container environment, ensuring that sensitive information is not stored in command-line histories
- **Pull the sentiment analysis API container image**
> Pull the sentiment analysis API container image (in the Dockerfile). Including the base image pull in the Dockerfile is necessary to customize and build upon it for your specific use case
</details>

----
Q: You are an AI engineer working on a Custom Vision project for object detection. The project uses the General domain and contains a trained model. You need to export the model for use on a network that is disconnected from the internet. What actions should you perform?
<details><summary>Show the answer</summary><p>

- **Export the model**
> After retraining the model in the compact domain, you need to export it so that it can be used on a network that is disconnected from the internet. Exporting the model generates a file that can be deployed offline
- **Change Domains to General (compact)**
> Changing the domain to General (compact) is necessary because compact models are optimized for export and offline use. The General (compact) domain ensures the model can run efficiently in a constrained environment without internet access
- **Retrain the model**
> Once the domain is changed to General (compact), retraining the model is essential to ensure it is properly adjusted to the new domain’s parameters. This step is crucial for maintaining the model's accuracy and performance in its new configuration
</details>

----
Q: A developer is building an application that allows users to upload images. The application needs to meet the following requirements:
- Extract text from uploaded images.
- Detect offensive language in the extracted text.
- Minimize development effort.
Which Azure AI services should the developer use to meet these requirements?
<details><summary>Show the answer</summary><p>

- **Text extraction: Azure AI Vision**
- **Profane language detection: Azure AI Content Safety**
> Azure AI Vision is ideal for extracting text from images, making it suitable for the text extraction requirement.
Azure AI Content Safety provides capabilities to detect and moderate offensive content, including profane language, thus addressing the need for profane language detection
</details>

----
Q: You are an AI engineer tasked with provisioning a QnA Maker service for a client. You create an App Service plan named AP2 in a new resource group named RG2. When you provision the QnA Maker service in RG2, which two Azure resources are automatically created in RG2 as part of the solution?
<details><summary>Show the answer</summary><p>

- **Azure App Service**
> Azure App Service is also created to host the QnA Maker runtime
- **Azure Cognitive Search**
> When you provision a QnA Maker service, Azure Cognitive Search is created to index and search the knowledge base
</details>

----
Q: You are tasked with setting up an enrichment pipeline for a collection of 75,000 scanned documents that contain text. The pipeline needs to perform both Optical Character Recognition (OCR) and text analytics using Azure AI Search. To ensure the solution is cost-effective, which resource should you link to the skillset to minimize expenses?
<details><summary>Show the answer</summary><p>

- **A new Cognitive Services resource using the F0 (free) pricing tier**
> Using a Cognitive Services resource with the F0 (free) pricing tier is the most cost-effective solution to perform OCR and text analytics on a large number of documents. The F0 tier provides limited free transactions which can help minimize costs while still meeting your requirements
</details>

----
Q: You are developing an online training solution that requires users' cameras and microphones to stay active. You need to monitor the video stream to detect when a user asks a question to the instructor. The solution should minimize development effort. What should you include in your solution?
<details><summary>Show the answer</summary><p>

- **Speech-to-text in the Azure AI Speech service**
> Speech-to-text in the Azure AI Speech service converts spoken words into text, making it easier to detect when a user asks a question. This minimizes development effort as it directly addresses the requirement to monitor and transcribe user speech
</details>

----
Q: You train a Custom Vision model to identify various plant species using the Environment domain. You plan to deploy the model as part of an app for iOS devices. You need to prepare the model for deployment.
What three actions should you perform?
<details><summary>Show the answer</summary><p>

- **Change the model domain**
> Changing the model domain is necessary to ensure the model is trained for the specific application requirements
- **Export the model**
> Exporting the model makes it available for deployment in the intended app, ready for use
- **Retrain the model**
> Retraining the model adapts it to the new domain, improving its accuracy and relevance
</details>

----
Q: A data analyst at Contoso Ltd. is tasked with implementing an image moderation solution to filter inappropriate content in user-uploaded images on their social platform. Which Azure AI service should they use to achieve this goal?
<details><summary>Show the answer</summary><p>

- **Azure AI Content Safety**
> Azure AI Content Safety is specifically designed to implement solutions for moderating content, including images, to ensure safety and appropriateness
</details>

----
Q: You plan to deploy an Azure OpenAI resource using an Azure Resource Manager (ARM) template. You need to ensure that the resource can handle 600 requests per minute. How should you complete the template?
<details><summary>Show the answer</summary><p>

```
{
  "type": "Microsoft.CognitiveServices/accounts/deployments",
  "apiVersion": "2023-05-01",
  "name": "arm-aoai-sample-resource/arm-je-std-deployment",
  "dependsOn": [
    "[resourceId('Microsoft.CognitiveServices/accounts', 'arm-aoai-sample-resource')]"
  ],
  "sku": {
    "name": "Standard",
    "capacity": 100
  },
  "properties": {
    "model": {
      "format": "OpenAI",
      ...
    }
  }
}
```
> Using "capacity" in the sku section of the ARM template with a value of 100 ensures the resource is configured to handle the required 600 requests per minute. The "capacity" parameter is designed to set the performance level required for the deployment
</details>

----
Q: You are an AI engineer tasked with developing an automated support system that responds to users in their native language. The system will support both Spanish and German. Which Azure AI services should you use to meet each requirement?
Requirements:
- Detect the language of incoming requests.
- Respond in the user's own language
<details><summary>Show the answer</summary><p>

- **Speech to Text**
> Speech to Text can be used to convert spoken language into text, which helps in detecting the language of incoming voice requests
- **Text to Speech**
> Text to Speech can be used to convert text responses into spoken language, allowing the system to respond in the user's own language
</details>

----
Q: A data scientist at a healthcare organization is developing an AI system to process patient data from various regions. The system needs to ensure that it provides equitable results for all patients, regardless of their demographics. Which two responsible AI principles should guide the monitoring of this system?
<details><summary>Show the answer</summary><p>

- **Fairness**
> This principle ensures that the AI system provides equitable results regardless of a user’s location or background. It involves minimizing bias in the AI system’s outcomes and providing equal opportunities for all users
- **Inclusiveness**
> This principle ensures that the AI system is accessible and usable by the widest possible range of people, regardless of their location or background. It involves considering the diverse characteristics of potential users during the design and deployment of the AI system
</details>

----
Q: You are a data engineer tasked with indexing a 30-GB video file stored in an AWS S3 bucket. The video file is named TrainingSession.mp4. You need to index TrainingSession.mp4 using the Azure AI Video Indexer website. What should you do?
<details><summary>Show the answer</summary><p>

- **From S3, create a pre-signed URL for TrainingSession.mp4, and then copy the URL to the Azure AI Video Indexer website**
> Creating a pre-signed URL provides secure, temporary access to the video file, allowing Azure AI Video Indexer to index it without needing to download and upload the large file
</details>

----
Q: An AI engineer at AdventureWorks needs to generate custom images for a marketing campaign. Which Azure AI service should they use to accomplish this?
<details><summary>Show the answer</summary><p>

- **Azure OpenAI DALL-E**
> Azure OpenAI DALL-E is a model specifically designed to generate images from textual descriptions, making it ideal for creating custom images for various purposes
</details>

----
Q: A data scientist at a manufacturing company is developing a predictive maintenance system. The system collects IoT sensor data from 50 industrial machines, each generating data every minute. To identify unusual values and predict machine failures, which Azure service should the data scientist use?
<details><summary>Show the answer</summary><p>

- **Anomaly Detector**
> The Anomaly Detector service is specifically designed to identify unusual patterns and anomalies in time series data, making it ideal for predictive maintenance
</details>

----
Q: You successfully run the following HTTP request:
```
POST https://management.azure.com/subscriptions/18c51a87-3a69-47a8-aedc-a54745f708a1/resourceGroups/RG1/providers/Microsoft.CognitiveServices/accounts/contoso1/regenerateKey?api-version=2017-04-18 Body{"keyName": "Key2"}
```
What is the result of this request?
<details><summary>Show the answer</summary><p>

- **The secondary subscription key was reset**
> The request specifically regenerates the key named "Key2", which corresponds to the secondary subscription key, resetting it
</details>

----
Q: An AI engineer is enhancing a language understanding model for a customer service chatbot and needs to enable active learning to improve model performance over time.
How should the engineer enable active learning?
<details><summary>Show the answer</summary><p>

- **Add log=true to the prediction endpoint query**
> This action enables logging, which is essential for active learning as it allows the model to gather data from user interactions and improve iteratively
</details>

----
Q: An AI engineer is developing a language understanding model for an e-commerce platform. The model needs to capture billing addresses from user input.
Which entity type should the engineer use for the billing address?
<details><summary>Show the answer</summary><p>

- **Machine learned**
> Machine learned entities are suitable for capturing complex and unstructured data like billing addresses, as they can adapt to various formats and nuances in user input
</details>

----
Q: A developer is preparing to upload speech samples to Azure Speech Studio for a project. The samples must be correctly formatted to ensure successful processing.
What is the best way to upload the speech samples?
<details><summary>Show the answer</summary><p>

- **Upload a zip file containing audio files in the .wav format and a corresponding text transcript file**
> Uploading a zip file containing .wav audio files and a corresponding text transcript file ensures that Speech Studio can process both audio and text data together effectively
</details>

----
Q: You are an AI engineer with an Azure IoT hub receiving sensor data from factory equipment. You need to build an app that:
- Detects anomalies across multiple correlated sensors.
- Identifies the root cause of equipment stops.
- Sends incident alerts.
- The solution must minimize development time.
Which Azure service should you use?
<details><summary>Show the answer</summary><p>

- **Azure Metrics Advisor**
> Azure Metrics Advisor is designed for anomaly detection and diagnostics, especially for time-series data from IoT devices. It can quickly identify anomalies, diagnose issues, and send alerts with minimal development effort
</details>

----
Q: A data engineer at a financial services company plans to enable server-side encryption for their Azure Cognitive Search service and use customer-managed keys (CMK) stored in Azure Key Vault. What are three implications of this planned change?
<details><summary>Show the answer</summary><p>

- **Query times will increase**
> Using server-side encryption with customer-managed keys can introduce additional latency due to the encryption and decryption processes
- **An Azure Key Vault is required**
> Azure Key Vault is necessary to manage and store the customer-managed keys used for encryption
- **Index size will increase**
> Encryption can increase the overall size of the index because of the overhead associated with storing encrypted data
</details>

----
Q: An AI engineer is building a Conversational Language Understanding model for a customer service chatbot for a financial services company. Users can speak or type their account numbers when prompted by the chatbot. The engineer needs to construct an entity to capture these account numbers accurately.
Which entity type should the engineer use?
<details><summary>Show the answer</summary><p>

- **Regex**
> Regex entities are used to identify patterns in text, making it suitable for capturing structured data like account numbers which follow a specific format
</details>

----
Q: You are developing an application that will recognize faults in components produced on a factory production line. The components are specific to your business. You need to use the Custom Vision API to help detect common faults.
Which three actions should you perform?
<details><summary>Show the answer</summary><p>

- **Upload and tag images**
> Uploading and tagging images provides the necessary data for training the model, helping it learn to detect faults
- **Create a project**
> Creating a project is the first step where you define the scope and purpose of your model
- **Train the classifier model**
> Training the classifier model uses the tagged images to develop the capability to identify faults in new images
</details>

----
Q: You are a data scientist using Azure Video Analyzer for Media to make company training videos searchable by identifying the people present. How should you configure the system?
<details><summary>Show the answer</summary><p>

- **Create person objects and upload face images for each individual**
> By creating person objects and uploading face images, Azure Video Analyzer can automatically recognize and tag individuals in the videos, enabling efficient search functionality
</details>

----
Q: A data engineer at a retail company is tasked with building a multilingual intelligent customer support chatbot. The chatbot must:
- Handle general chit-chat.
- Access and retrieve information from a knowledge base.
- Understand and process messages in multiple languages.
- Analyze the sentiment of user messages.
- Automatically use the appropriate language model for each interaction.
Which combination of Azure services should the data engineer integrate to fulfill these requirements?
<details><summary>Show the answer</summary><p>

- **Language Understanding (LUIS), Text Analytics, and Azure AI Language (Custom Question Answering)**
> Language Understanding (LUIS) handles chit-chat and intent recognition, ensuring that the chatbot can understand and respond to user inputs naturally. Text Analytics provides sentiment analysis and language detection, enabling the chatbot to process emotions and identify the language of messages. Azure AI Language (Custom Question Answering) (a replacement for QnA Maker) provides access to a multi-language knowledge base, making it suitable for multilingual scenarios. Together, these services fulfill all the requirements for the chatbot
</details>

----
