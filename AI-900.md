
## Questions

Q: Which natural language processing (NLP) workload is used to generate closed caption text for live presentations?
<details><summary>Show the answer</summary><p>

- **Azure AI Speech**
> Azure AI Speech provides speech-to-text and text-to-speech capabilities through speech recognition and synthesis. You can use prebuilt and custom Speech service models for a variety of tasks, from transcribing audio to text with high accuracy to identifying speakers in conversations, creating custom voices, and more. [Source](https://learn.microsoft.com/training/modules/recognize-synthesize-speech/1-introduction)
</details>

---
Q: Which type of artificial intelligence (AI) workload provides the ability to generate bounding boxes that identify the locations of different types of vehicles in an image?
<details><summary>Show the answer</summary><p>

- **object detection**
> Object detection provides the ability to generate bounding boxes identifying the locations of different types of vehicles in an image. The other answer choices also process images, but their outcomes are different. [Source](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/4-understand-computer-vision)
</details>

---
Q: Which type of service provides a platform for conversational artificial intelligence (AI)?
<details><summary>Show the answer</summary><p>

- **Azure AI Bot Service**
> Azure AI Bot Service provides a platform for conversational artificial intelligence (AI), which designates the ability of software agents to participate in a conversation. Azure AI Translator is part of Natural language processing (NLP), but it does not serve as a platform for conversational AI. Azure AI Vision deals with image processing. Azure AI Document Intelligence extracts information from scanned forms and invoices. [Source](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/5-understand-natural-language-process)
</details>

---
Q: Which two artificial intelligence (AI) workload features are part of the Azure AI Vision service? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Optical character recognition (OCR)**
- **Spatial analysis**
> OCR and Spatial Analysis are part of the Azure AI Vision service. Sentiment analysis, entity recognition, and key phrase extraction are not part of the computer vision service. [Source](https://learn.microsoft.com/training/paths/explore-computer-vision-microsoft-azure/)
</details>

---
Q: Which principle of responsible artificial intelligence (AI) has the objective of ensuring that AI solutions benefit all parts of society regardless of gender or ethnicity?
<details><summary>Show the answer</summary><p>

- **inclusiveness**
> The inclusiveness principle is meant to ensure that AI solutions empower and engage everyone, regardless of criteria such as physical ability, gender, sexual orientation, or ethnicity. Privacy and security, reliability and safety, and accountability do not discriminate based on these criteria but also do not emphasize the significance of bringing benefits to all parts of society. [Source](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/8-understand-responsible-ai)
</details>

---
Q: Which principle of responsible artificial intelligence (AI) involves evaluating and mitigating the bias introduced by the features of a model?
<details><summary>Show the answer</summary><p>

- **fairness**
> Fairness involves evaluating and mitigating the bias introduced by the features of a model. Privacy is meant to ensure that privacy provisions are included in AI solutions. Transparency provides clarity regarding the purpose of AI solutions, the way they work, and their limitations. Accountability is focused on ensuring that AI solutions meet clearly defined ethical and legal standards. [Source](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/8-understand-responsible-ai)
</details>

---
Q: Which principle of responsible artificial intelligence (AI) is applied in the design of an AI system to ensure that users understand the constraints and limitations of AI?
<details><summary>Show the answer</summary><p>

- **Transparency**
> The transparency principle states that AI systems must be designed in such a way that users are made fully aware of the purpose of the systems, how they work, and which limitations can be expected during use. The inclusiveness principle states that AI systems must empower people in a positive and engaging way. Fairness is applied to AI systems to ensure that users of the systems are treated fairly. Privacy and security principles are applied to the design of AI systems to ensure that the systems are secure and to respect user privacy. [Source](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/8-understand-responsible-ai)
</details>

---
Q: A bank is developing a new artificial intelligence (AI) system to support the process of accepting or rejecting mortgage applications.

Which two issues should be considered as part of the responsible AI principle of fairness to avoid biased decision-making? Each correct answer presents part of the solution.
<details><summary>Show the answer</summary><p>

- **Ethnicity**
- **Gender**
> The AI system must be designed to ensure that biased decision-making is avoided and not based on factors such as ethnicity and gender. The system will consider salary, payment history, and credit utilization. These are standard metrics. [Source](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/8-understand-responsible-ai)
</details>

---
Q: Which principle of responsible artificial intelligence (AI) ensures that an AI system meets any legal and ethical standards it must abide by?
<details><summary>Show the answer</summary><p>

- **accountability**
> The accountability principle ensures that AI systems are designed to meet any ethical and legal standards that are applicable. The privacy and security principle states that AI systems must be designed to protect any personal and/or sensitive data. The inclusiveness principle states that AI systems must empower people in a positive and engaging way. The fairness principle is applied to AI systems to ensure that users of the systems are treated fairly. [Source<sup>1</sup>](https://learn.microsoft.com/training/paths/explore-computer-vision-microsoft-azure/) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/8-understand-responsible-ai)
</details>

---
Q: A company is currently developing driverless agriculture vehicles to help harvest crops. The vehicles will be deployed alongside people working in the crop fields, and as such, the company will need to carry out robust testing.

Which principle of responsible artificial intelligence (AI) is most important in this case?
<details><summary>Show the answer</summary><p>

- **Reliability and safety**
> The reliability and safety principles are of paramount importance here as they require an AI system to work alongside people in a physical environment by using AI-controlled machinery. The system must function safely while ensuring no harm will come to human life. [Source](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/8-understand-responsible-ai)
</details>

---
Q: Which type of machine learning algorithm predicts a numeric label associated with an item based on that item’s features?
<details><summary>Show the answer</summary><p>

- **Regression**
> The regression algorithms are used to predict numeric values. Clustering algorithms group data points that have similar characteristics. Classification algorithms are used to predict the category to which an input value belongs. Unsupervised learning is a category of learning algorithms that includes clustering but not regression or classification. [Source<sup>1</sup>](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/) [Source<sup>3</sup>](https://learn.microsoft.com/training/modules/understand-classification-machine-learning/2-what-is-classification) [Source<sup>3</sup>](https://learn.microsoft.com/training/modules/train-evaluate-cluster-models/2-what-is-clustering)
</details>

---
Q: Which type of machine learning algorithm finds the optimal way to split a dataset into groups without relying on training and validating label predictions?
<details><summary>Show the answer</summary><p>

- **Clustering**
> A clustering algorithm is an example of unsupervised learning, which groups data points that have similar characteristics without relying on training and validating label predictions. Supervised learning is a category of learning algorithms that includes regression and classification but not clustering. Classification and regression algorithms are examples of supervised machine learning. [Source<sup>1</sup>](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/understand-classification-machine-learning/2-what-is-classification) [Source<sup>3</sup>](https://learn.microsoft.com/training/modules/train-evaluate-cluster-models/2-what-is-clustering)
</details>

---
Q: A company deploys an online marketing campaign to social media platforms for a new product launch. The company wants to use machine learning to measure the sentiment of users on the Twitter platform who made posts in response to the campaign.

Which type of machine learning is this?
<details><summary>Show the answer</summary><p>

- **Classification**
> Classification is used to predict categories of data. It can predict which category or class an item of data belongs to. In this example, sentiment analysis can be carried out on Twitter posts with a numeric value applied to them to identify and classify positive or negative sentiments. Clustering is a machine learning type that analyzes unlabeled data to find similarities in the data. Regression is a machine-learning scenario that is used to predict numeric values. Data transformation is not a machine learning type. [Source](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/7-clustering)
</details>

---
Q: In a regression machine learning algorithm, how are features and labels handled in a validation dataset?
<details><summary>Show the answer</summary><p>

- **Features are used to generate predictions for the label, which are compared to the actual label values**
> In a regression machine learning algorithm, features are used to generate predictions for the label, which is compared to the actual label value. There is no direct comparison of features or labels between the validation and training datasets. [Source](https://learn.microsoft.com/training/modules/train-evaluate-regression-models/2-what-is-regression)
</details>

---
Q: In a regression machine learning algorithm, what are the characteristics of features and labels in a training dataset?
<details><summary>Show the answer</summary><p>

- **Known feature and label values**
> In a regression machine learning algorithm, a training set contains known feature and label values. [Source](https://learn.microsoft.com/training/modules/train-evaluate-regression-models/2-what-is-regression)
</details>

---
Q: A company is using machine learning to predict various aspects of its e-scooter hire service dependent on weather. This includes predicting the number of hires, the average distance travelled, and the impact on e-scooter battery levels.

For the machine learning model, which two attributes are the features? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Weather temperature**
- **Weekday or weekend**
> Weather temperature and weekday or weekend are features that provide a weather temperature for a given day and a value based on whether the day is on a weekend or weekday. These are input variables for the model to help predict the labels for e-scooter battery levels, number of hires, and distance travelled. E-scooter battery levels, number of hires, and distance travelled are numeric labels you are attempting to predict through the machine-learning model. [Source](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/)
</details>

---
Q: What is the purpose of a validation dataset used as part of the development of a machine learning model?
<details><summary>Show the answer</summary><p>

- **Evaluating the trained model**
> The validation dataset is a sample of data held back from a training dataset. It is then used to evaluate the performance of the trained model. Cleaning missing data is used to detect missing values and perform operations to fix the data or create new values. Feature engineering is part of preparing the dataset and related data transformation processes. Summarizing the data is used to provide summary statistics, such as the mean or count of distinct values in a column. [Source](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/4-regression)
</details>

---
Q: You need to create an automated machine learning (automated ML) model.

Which resource should you create first in Azure Machine Learning Studio?
<details><summary>Show the answer</summary><p>

- **A dataset**
> A dataset is required to create an automated machine learning (automated ML) run. A workspace must be created before you can access Machine Learning Studio. An Azure container instance and an AKS cluster can be created as a deployment target after the training of a model is complete. [Source](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/)
</details>

---
Q: You need to use Azure Machine Learning to train a regression model.

What should you create in a Machine Learning studio?
<details><summary>Show the answer</summary><p>

- **A job**
> A job must be created in a Machine Learning studio to use Machine Learning to train a regression model. A workspace must be created before you can access Machine Learning studio. An Azure container instance and an AKS cluster can be created as a deployment target after the training of a model is complete. [Source](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/)
</details>

---
Q: You need to use the Azure Machine Learning designer to train a machine learning model.

What should you do first as a Machine Learning designer?
<details><summary>Show the answer</summary><p>

- **Create a pipeline**
> Before you can start training a machine learning model, you must first create a pipeline in the Machine Learning designer. This is followed by adding a dataset, adding training modules, and eventually deploying a service. [Source](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/4-regression)
</details>

---
Q: You train a regression model by using automated machine learning (automated ML) in the Azure Machine Learning studio. You review the best model summary.

You need to publish the model for others to use on the internet.

What should you do next?
<details><summary>Show the answer</summary><p>

- **Deploy the model to an endpoint**
> You can deploy the best-performing model for client applications to use over the internet using an endpoint. Compute clusters are used to train the model and are created directly after you create a Machine Learning workspace. Before you can test the model’s endpoint, you must deploy it first to an endpoint. Automated ML performs the validation automatically, so you do not need to split the dataset. [Source<sup>1</sup>](https://learn.microsoft.com/azure/machine-learning/concept-automated-ml) [Source<sup>2</sup>](https://learn.microsoft.com/en-us/training/modules/fundamentals-machine-learning/4-regression)
</details>

---
Q: What is an unsupervised machine learning algorithm module for training models in the Azure Machine Learning Designer?
<details><summary>Show the answer</summary><p>

- **K-Means Clustering**
> K-means clustering is an unsupervised machine learning algorithm component used for training clustering models. You can use unlabeled data with this algorithm. Linear regression and classification are supervised machine learning algorithm components. You need labelled data to use these algorithms. Normalize Data is not a machine learning algorithm module. [Source](https://learn.microsoft.com/training/modules/fundamentals-machine-learning/7-clustering)
</details>

---
Q: Which artificial intelligence (AI) technique should be used to extract the name of a store from a photograph displaying the storefront?
<details><summary>Show the answer</summary><p>

- **Optical character recognition (OCR)**
> OCR provides the ability to detect and read text in images. NLP is an area of AI that deals with identifying the meaning of a written or spoken language but not detecting or reading text in images. Image classification classifies images based on their contents. Semantic segmentation provides the ability to classify individual pixels in an image. [Source](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/4-understand-computer-vision)
</details>

---
Q: Which computer vision solution provides the ability to identify a person's age based on a photograph?
<details><summary>Show the answer</summary><p>

- **Facial detection**
> Facial detection provides the ability to detect and analyze human faces in an image, including identifying a person's age based on a photograph. Image classification classifies images based on their contents. Object detection provides the ability to generate bounding boxes identifying the locations of different types of vehicles in an image. Semantic segmentation provides the ability to classify individual pixels in an image. [Source<sup>1</sup>](https://learn.microsoft.com/training/modules/analyze-images-computer-vision/2-image-analysis-azure) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/get-started-ai-fundamentals/4-understand-computer-vision)
</details>

---
Q: Which process allows you to use object detection?
<details><summary>Show the answer</summary><p>

- **Tracking livestock in a field**
> Object detection can be used to track livestock animals, such as cows, to support their safety and welfare. For example, a farmer can track whether a particular animal has not been mobile. Sentiment analysis is used to return a numeric value based on the analysis of a text. Employee access to a secure building can be achieved by using facial recognition. Extracting text from manuscripts is an example of a computer vision solution that uses optical character recognition (OCR). [Source](https://learn.microsoft.com/training/modules/detect-objects-images-custom-vision/1a-what-is-object-detection)
</details>

---
Q: What can be used for an attendance system that can scan handwritten signatures?
<details><summary>Show the answer</summary><p>

- **Optical character recognition (OCR)**
> OCR is used to extract text and handwriting from images. In this case, it can be used to extract signatures for attendance purposes. Face detection can detect and verify human faces, not text, from images. Object detection can detect multiple objects in an image by using bounding box coordinates. It is not used to extract handwritten text. Image classification is the part of computer vision that is concerned with the primary contents of an image. [Source](https://learn.microsoft.com/training/modules/read-text-computer-vision/)
</details>

---
Q: Which three parts of the machine learning process does the Azure AI Vision eliminate the need for? Each correct answer presents part of the solution.
<details><summary>Show the answer</summary><p>

- **Choosing a model**
- **Evaluating a model**
- **Training a model**
> The computer vision service eliminates the need to choose, train, and evaluate a model by providing pre-trained models. To use computer vision, you must create an Azure resource. The use of computer vision involves inferencing. [Source](https://learn.microsoft.com/training/modules/analyze-images-computer-vision/1-introduction)
</details>

---
Q: Which two specialized domain models are supported by using the Azure AI Vision service? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Celebrities**
- **Landmarks**
> The Azure AI Vision service supports the celebrities and landmarks specialized domain models. It does not support specialized animal, car, or plant domain models. [Source](https://learn.microsoft.com/training/modules/analyze-images-computer-vision/2-image-analysis-azure)
</details>

---
Q: Which two prebuilt models allow you to use the Azure AI Document Intelligence service to scan information from international passports and sales accounts? Each correct answer presents part of the solution
<details><summary>Show the answer</summary><p>

- **ID document model**
- **Invoice model**
> The invoice model extracts key information from sales invoices and is suitable for extracting information from sales account documents. The ID document model is optimized to analyze and extract key information from US driver’s licenses and international passport biographical pages. The business card model, receipt model, and language model are not suitable for extracting information from passports or sales account documents. [Source<sup>1</sup>](https://learn.microsoft.com/training/modules/analyze-receipts-form-recognizer/) [Source<sup>2</sup>](https://learn.microsoft.com/azure/applied-ai-services/form-recognizer/concept-model-overview?view=form-recog-3.0.0)
</details>

---
Q: Which two Azure AI Document Intelligence models include identifying common data fields as part of its data extraction capabilities? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Business card model**
- **Invoice model**
> The business card model analyzes and extracts key information from business card images and includes common data field extractions, such as name and email. The invoice model extracts key information from sales invoices and includes common data fields used in invoices for extraction. The read model, layout model, and general document model do not identify and extract common data fields. [Source<sup>1</sup>](https://learn.microsoft.com/azure/applied-ai-services/form-recognizer/concept-model-overview?view=form-recog-3.0.0) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/analyze-receipts-form-recognizer/)
</details>

---
Q: When using the Face Detect API of the Azure AI Face service, which feature helps identify whether a human face has glasses or headwear?
<details><summary>Show the answer</summary><p>

- **Face attributes**
> Face attributes are a set of features that can be detected by the Face Detect API. Attributes such as accessories (glasses, mask, headwear etc.) can be detected. Face rectangle, face ID, and face landmarks do not allow you to determine whether a person is wearing glasses or headwear. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/computer-vision/overview-identity) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/detect-analyze-faces/)
</details>

---
Q: When using the Azure AI Face service, what should you use to perform one-to-many or one-to-one face matching? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **face identification**
- **face verification**
> Face identification in the Azure AI Face service can address one-to-many matching of one face in an image to a set of faces in a secure repository. Face verification has the capability for one-to-one matching of a face in an image to a single face from a secure repository or a photo to verify whether they are the same individual. Face attributes, the find similar faces operation, and Azure AI Custom Vision do not verify the identity of a face. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/computer-vision/overview-identity) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/detect-analyze-faces/)
</details>

---
Q: Which natural language processing (NLP) technique assigns values to words such as plant and flower, so that they are considered closer to each other than a word such as airplane?
<details><summary>Show the answer</summary><p>

- **Vectorization**
> Vectorization captures semantic relationships between words by assigning them to locations in n-dimensional space. Lemmatization, also known as stemming, normalizes words before counting them. Frequency analysis counts how often a word appears in a text. N-grams extend frequency analysis to include multi-term phrases. [Source](https://learn.microsoft.com/training/modules/analyze-text-with-text-analytics-service/1-introduction)
</details>

---
Q: Which part of speech synthesis in natural language processing (NLP) involves breaking text into individual words such that each word can be assigned phonetic sounds?
<details><summary>Show the answer</summary><p>

- **Tokenization**
> Tokenization is part of speech synthesis that involves breaking text into individual words such that each word can be assigned phonetic sounds. Transcribing is part of speech recognition, which involves converting speech into a text representation. Key phrase extraction is part of language processing, not speech synthesis. Lemmatization, also known as stemming, is part of language processing, not speech synthesis. [Source](https://learn.microsoft.com/training/modules/recognize-synthesize-speech/)
</details>

---
Q: Which Azure AI Service for Language feature can be used to analyze online user reviews to identify whether users view a product positively or negatively?
<details><summary>Show the answer</summary><p>

- **Sentiment analysis**
> Sentiment analysis provides sentiment labels, such as negative, neutral, and positive, based on a confidence score from text analysis. This makes it suitable for understanding user sentiment for product reviews. The named entity recognition, key phrase extraction, and language detection features cannot perform sentiment analysis for product reviews.[Source<sup>1</sup>](https://learn.microsoft.com/training/modules/analyze-text-with-text-analytics-service/) [Source<sup>2</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/sentiment-opinion-mining/overview) [Source<sup>3</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/sentiment-opinion-mining/overview)
</details>

---
Q: Which two Azure AI Services features can be used to enable both text-to-text and speech-to-text between multiple languages? Each correct answer presents part of the solution.
<details><summary>Show the answer</summary><p>

- **The Speech service**
- **The Translator service**
> The Azure AI Speech service can be used to generate spoken audio from a text source for text-to-speech translation. The Azure AI Translator service directly supports text-to-text translation in more than 60 languages. Key phrase extraction, Conversational Language Understanding, and language detection are not used for language translation for text-to-text and speech-to-text translation. [Source<sup>1</sup>](https://learn.microsoft.com/training/modules/translate-text-with-translation-service/) [Source<sup>2</sup>](https://learn.microsoft.com/azure/cognitive-services/translator/) [Source<sup>3</sup>](https://learn.microsoft.com/azure/cognitive-services/translator/)
</details>

---
Q: Which three values are returned by the language detection feature of the Azure AI Language service in Azure?
<details><summary>Show the answer</summary><p>

- **ISO 6391 Code**
- **Language Name**
- **Score**
> Language Name, ISO 6391 Code, and Score are three values returned by the Language service of natural language processing (NLP) in Azure. Bounding box coordinates are returned by the Azure AI Vision services in Azure. Wikipedia URL is one of potential values returned by entity linking of entity recognition. [Source](https://learn.microsoft.com/training/modules/analyze-text-with-text-analytics-service/2-get-started-azure)
</details>

---
Q: Which type of translation does the Azure AI Translator service support?
<details><summary>Show the answer</summary><p>

- **Text-to-text**
> The Azure AI Translator service supports text-to-text translation, but it does not support speech-to-text, text-to-speech, or speech-to-speech translation. [Source](https://learn.microsoft.com/training/modules/translate-text-with-translation-service/2-get-started-azure)
</details>

---
Q: Which three features are elements of the Azure AI Language Service? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Entity Linking**
- **Personally Identifiable Information (PII) detection**
- **Sentiment analysis**
> Entity Linking, PII detection, and sentiment analysis are all elements of the Azure AI Service for Azure AI Language. Azure AI Vision deals with image processing. Azure AI Content Moderator is an Azure AI Services service that is used to check text, image, and video content for material that is potentially offensive. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/language-service/overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/paths/explore-natural-language-processing/)
</details>

---
Q: Which feature of the Azure AI Translator service is available only to Custom Translator?
<details><summary>Show the answer</summary><p>

- **Model training with a dictionary**
> Model training with a dictionary can be used with Custom Translator when you do not have enough parallel sentences to meet the 10,000 minimum requirements. The resulting model will typically complete training much faster than with full training and will use the baseline models for translation along with the dictionaries you have added. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/translator/custom-translator/overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/intro-to-translator/)
</details>

---
Q: Which feature of the Azure AI Speech service can identify distinct user voices?
<details><summary>Show the answer</summary><p>

- **Speech recognition**
> Speech recognition uses audio data to analyze speech and determine recognizable patterns that can be mapped to distinct user voices. Azure AI Speech synthesis is concerned with vocalizing data, usually by converting text to speech. Azure AI Speech translation is concerned with multilanguage translation of speech. Language identification is used to identify languages spoken in audio when compared against a list of supported languages. [Source<sup>1</sup>](https://learn.microsoft.com/azure/cognitive-services/speech-service/speaker-recognition-overview) [Source<sup>2</sup>](https://learn.microsoft.com/training/modules/recognize-synthesize-speech/)
</details>

---
Q: Which three sources can be used to generate questions and answers for a knowledge base? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **A webpage**
- **An existing FAQ document**
- **Manually entered data**
> A webpage or an existing document, such as a text file containing question and answer pairs, can be used to generate a knowledge base. You can also manually enter the knowledge base question-and-answer pairs. You cannot directly use an image or an audio file to import a knowledge base. [Source](https://learn.microsoft.com/training/modules/build-faq-chatbot-qna-maker-azure-bot-service/)
</details>

---
Q: Select the answer that correctly completes the sentence.

[Answer choice] use plugins to provide end users with the ability to get help with common tasks from a generative AI model.
<details><summary>Show the answer</summary><p>

- **Copilots**
> Copilots are often integrated into applications to provide a way for users to get help with common tasks from a generative AI model. Copilots are based on a common architecture, so developers can build custom copilots for various business-specific applications and services. [Source](https://learn.microsoft.com/training/modules/fundamentals-generative-ai/5-copilots)
</details>

---
Q: At which layer can you apply content filters to suppress prompts and responses for a responsible generative AI solution?
<details><summary>Show the answer</summary><p>

- **Safety system**
> The safety system layer includes platform-level configurations and capabilities that help mitigate harm. For example, the Azure OpenAI service includes support for content filters that apply criteria to suppress prompts and responses based on the classification of content into four severity levels (safe, low, medium, and high) for four categories of potential harm (hate, sexual, violence, and self-harm). [Source](https://learn.microsoft.com/training/modules/responsible-generative-ai/5-mitigate-harms)
</details>

---
Q: Select the answer that correctly completes the sentence.

[Answer choice] can used to identify constraints and styles for the responses of a generative AI model.
<details><summary>Show the answer</summary><p>

- **System messages**
> System messages should be used to set the context for the model by describing expectations. Based on system messages, the model knows how to respond to prompts. The other techniques are also used in generative AI models but for other use cases. [Source](https://learn.microsoft.com/training/modules/fundamentals-generative-ai/6-writing-prompts)
</details>

---
Q: Which two capabilities are examples of a GPT model? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Create natural language**
- **Understand natural language**
> Azure OpenAI natural language models can take in natural language and generate responses. GPT models are excellent at both understanding and creating natural language. [Source](https://learn.microsoft.com/training/modules/explore-azure-openai/5-understand-openai-natural-language)
</details>

---
Q: Which three capabilities are examples of image generation features for a generative AI model? Each correct answer presents a complete solution.
<details><summary>Show the answer</summary><p>

- **Creating variations of an image**
- **Editing an image**
- **New image creation**
> Image generation models can take a prompt, a base image, or both, and create something new. These generative AI models can create both realistic and artistic images, change the layout or style of an image, and create variations of a provided image. [Source](https://learn.microsoft.com/training/modules/explore-azure-openai/7-understand-openai-image-generation)
</details>

---
Q: You plan to develop an image processing solution that will use DALL-E as a generative AI model.

Which capability is NOT supported by the DALL-E model?
<details><summary>Show the answer</summary><p>

- **Image description**
> Image description is not a capability included in the DALL-E model, therefore, it is not a use case that can be implemented by using DALL-E, while the other three capabilities are offered by DALL-E in Azure OpenAI. [Source](https://learn.microsoft.com/training/modules/explore-azure-openai/7-understand-openai-image-generation)
</details>

---
Q: Which generative AI model is used to generate images based on natural language prompts?
<details><summary>Show the answer</summary><p>

- **DALL-E**
> DALL-E is a model that can generate images from natural language. GPT-4 and GPT-3.5 can understand and generate natural language and code but not images. Embeddings can convert text into numerical vector form to facilitate text similarity. Whisper can transcribe and translate speech to text. [Source<sup></sup>](https://learn.microsoft.com/training/modules/explore-azure-openai/7-understand-openai-image-generation) [Source<sup></sup>](https://learn.microsoft.com/azure/ai-services/openai/concepts/models)
</details>

---
Q: Select the answer that correctly completes the sentence.

[Answer choice] can search, classify, and compare sources of text for similarity.
<details><summary>Show the answer</summary><p>

- **Embeddings**
> Embeddings is an Azure OpenAI model that converts text into numerical vectors for analysis. Embeddings can be used to search, classify, and compare sources of text for similarity. [Source](https://learn.microsoft.com/training/modules/explore-azure-openai/4-how-to-use-azure-openai)
</details>

---
